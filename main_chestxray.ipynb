{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main_chestxray.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMyg9CRwuoy1E8dt0d8EnEF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reizkian/chestxray/blob/master/main_chestxray.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shtqjJEl4Mtv"
      },
      "source": [
        "# **Chest XRay - Pneumonia Identification**\n",
        "\n",
        "<p align=\"justify\">\n",
        "The 2019 novel coronavirus (COVID-19) presents several unique features. While the diagnosis is confirmed using polymerase chain reaction (PCR), infected patients with pneumonia may present on chest X-ray and computed tomography (CT) images with a pattern that is only moderately characteristic for the human eye Ng, 2020. COVID-19â€™s rate of transmission depends on our capacity to reliably identify infected patients with a low rate of false negatives. In addition, a low rate of false positives is required to avoid further increasing the burden on the healthcare system by unnecessarily exposing patients to quarantine if that is not required. Along with proper infection control, it is evident that timely detection of the disease would enable the implementation of all the supportive care required by patients affected by COVID-19.\n",
        "</p>\n",
        "\n",
        "<p align=\"justify\">\n",
        "In late January, a Chinese team published a paper detailing the clinical and paraclinical features of COVID-19. They reported that patients present abnormalities in chest CT images with most having bilateral involvement Huang 2020. Bilateral multiple lobular and subsegmental areas of consolidation constitute the typical findings in chest CT images of intensive care unit (ICU) patients on admission Huang 2020. In comparison, non-ICU patients show bilateral ground-glass opacity and subsegmental areas of consolidation in their chest CT images Huang 2020. In these patients, later chest CT images display bilateral ground-glass opacity with resolved consolidation Huang 2020.\n",
        "</p>\n",
        "\n",
        "<p align=\"justify\">\n",
        "COVID is possibly better diagnosed using radiological imaging Fang, 2020 and Ai 2020.\n",
        "</p>\n",
        "\n",
        "\n",
        "**citation**\n",
        "\n",
        "[1] Joseph Paul Cohen and Paul Morrison and Lan Dao. COVID-19 image data collection, arXiv, 2020. https://github.com/ieee8023/covid-chestxray-dataset\n",
        "\n",
        "[2] https://github.com/JordanMicahBennett/SMART-CT-SCAN_BASED-COVID19_VIRUS_DETECTOR/\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TCdz2pa5d4I"
      },
      "source": [
        "## Data Preparation\n",
        "\n",
        "**The 1.11GB images of Chest X-Ray canbe downloaded directly from:**\n",
        "\n",
        "https://www.kaggle.com/alifrahman/chestxraydataset uploaded on kaggle by Alif Rahman 31 August 2020"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kwA0rHh5ha2"
      },
      "source": [
        "### download data\n",
        "\n",
        "Before we can import data from Kaggle to google.colab, we need to download the API token by **Login to Kaggle > My Account > Home > Create New API Token**. The API token wil be downloaded in the format of **kaggle.json**, then we need to upload it to goole colab hosted runtime.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5shX5mp8aot"
      },
      "source": [
        "# upload your 'kaggle.json' to hosted runtime\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVUj4fE--UGt"
      },
      "source": [
        "we need to do several adjustment such as installing kaggle library using pip and so on, until we adjust the access permisions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OW71rr_4-Lct"
      },
      "source": [
        "# Install kaggle library \n",
        "!pip install -q kaggle\n",
        "# Make \".kaggle\" directory in root directory\n",
        "!mkdir -p ~/.kaggle\n",
        "# Copy the API token to the kaggle directory\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "# Check the directory\n",
        "!ls ~/.kaggle\n",
        "# Adjust access permissions\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dn1zGV6s-4IG"
      },
      "source": [
        "The cell bellow contains the command to download the data into your hosted directory (google server). Basicly you just migrated the whole dataset from kaggle's server into google's server. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdFp_DN9-svY"
      },
      "source": [
        "# Download the data\n",
        "# you need to copy the API command from the kaggle link above\n",
        "!kaggle datasets download -d alifrahman/chestxraydataset "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7d94C6LOUjw"
      },
      "source": [
        "# unzip the data\n",
        "!unzip -q chestxraydataset.zip -d .\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsEcB7fVB2eR"
      },
      "source": [
        "we need to specify the specific path for train and test data, and each folder containing PNEUMONIA and NORMAL images dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyg8UBiH__Ag"
      },
      "source": [
        "import os\n",
        "# label\n",
        "pneumo = \"PNEUMONIA\"\n",
        "normal = \"NORMAL\"\n",
        "\n",
        "base_directory = \"/content/chest_xray\"\n",
        "# Train dataset directory\n",
        "train_dir = os.path.join(base_directory,\"train\") \n",
        "train_dir_pneumo = os.path.join(train_dir,pneumo)\n",
        "train_dir_normal = os.path.join(train_dir,normal)\n",
        "# Test dataset directory\n",
        "test_dir = os.path.join(base_directory,\"test\")\n",
        "test_dir_pneumo = os.path.join(test_dir,pneumo)\n",
        "test_dir_normal = os.path.join(test_dir,normal)\n",
        "\n",
        "print(\"CHECK SPECIFIC PATH HAS BEEN CREATED SUCCESSFULLY\")\n",
        "print()\n",
        "print(base_directory)\n",
        "print(\"-------------------------------------------\")\n",
        "print(train_dir)\n",
        "print(train_dir_pneumo)\n",
        "print(train_dir_normal)\n",
        "print(\"-------------------------------------------\")\n",
        "print(test_dir)\n",
        "print(test_dir_pneumo)\n",
        "print(test_dir_normal)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJaI9ZJdFxX7"
      },
      "source": [
        "# PREVIEW RANDOM IMAGES IN TRAIN DATA\n",
        "# INSPECT RAW DATA BEFORE AUGMENT\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "nrows = 2\n",
        "ncols = 4\n",
        "img_index = int(nrows*ncols / 2)\n",
        "\n",
        "# Set up matplotlib fig, and size it to fit 2x4 pics\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols*4, nrows*4)\n",
        "\n",
        "\n",
        "def RandomSamplingClassPath(path, number_of_images):\n",
        "  \"\"\"\n",
        "  take a directory path (eg. TRAIN dir which contain 2 class), \n",
        "  and return number_of_images path of the sampled images \n",
        "  \"\"\"\n",
        "  fnames = os.listdir(path)\n",
        "  fnames = (tf.random.shuffle(fnames)[:number_of_images]).numpy()\n",
        "  fnames = [tf.compat.as_str(fname) for fname in fnames]\n",
        "  fnames = [os.path.join(path, fname) for fname in fnames]\n",
        "  return fnames\n",
        "\n",
        "# Pick random image from train normal\n",
        "normal_images = RandomSamplingClassPath(train_dir_normal, img_index)\n",
        "# Pick random image from train pneumo\n",
        "pneumonia_images =RandomSamplingClassPath(train_dir_pneumo, img_index)\n",
        "\n",
        "print(\"SAMPLE OF TRAINING IMAGES (Before Augmentation)\")\n",
        "for i, img_path in enumerate(normal_images + pneumonia_images):\n",
        "    # Set up subplot; subplot indices start at 1\n",
        "    sp = plt.subplot(nrows, ncols, i+1)\n",
        "    sp.axis('Off') # Don't show axes (or gridlines)\n",
        "    if i < len(normal_images):\n",
        "        plt.title('NORMAL', fontweight='bold')\n",
        "    else:\n",
        "        plt.title('PNEUMONIA', fontweight='bold')\n",
        "    img = plt.imread(img_path)\n",
        "    plt.imshow(img,cmap=\"bone\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cARc67w_DLGq"
      },
      "source": [
        "### Preprocessing data\n",
        "We implement image augmentation (rescale, rotation, zoom, shear, flip, etc) from the HARD DRIVE before it get processed in the RAM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjG0bK_eEB7p"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "batch_size = 20 # load 20 batch of images per preprocessing and for later training\n",
        "target_size = (256,256) # resize into (256,256) pixel\n",
        "\n",
        "# Data Generator (to specify the augmentation)\n",
        "train_datagen = ImageDataGenerator(rescale = 1.0/255,\n",
        "                                   rotation_range = 3,\n",
        "                                   #width_shift_range = 0.2,\n",
        "                                   #height_shift_range = 0.2,\n",
        "                                   #shear_range = 0.1,\n",
        "                                   horizontal_flip=True,\n",
        "                                   zoom_range=0.1,\n",
        "                                   #featurewise_std_normalization=True,\n",
        "                                   #featurewise_center=True,\n",
        "                                   #fill_mode=\"nearest\"\n",
        "                                   )\n",
        "test_datagen = ImageDataGenerator(rescale = 1.0/255)\n",
        "\n",
        "# Specify Image Class Name\n",
        "classes = [\"NORMAL\",\"PNEUMONIA\"]\n",
        "\n",
        "# Train Generator (Agmentation done pre loading on RAM)\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    shuffle=True,\n",
        "                                                    batch_size=batch_size,\n",
        "                                                    #color_mode=\"grayscale\",\n",
        "                                                    class_mode=\"binary\",\n",
        "                                                    classes=classes,\n",
        "                                                    target_size=target_size\n",
        "                                                    )\n",
        "test_generator = test_datagen.flow_from_directory(test_dir,\n",
        "                                                  batch_size=batch_size,\n",
        "                                                  #color_mode=\"grayscale\",\n",
        "                                                  class_mode=\"binary\",\n",
        "                                                  classes=classes,\n",
        "                                                  target_size=target_size\n",
        "                                                  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jx6dABGNLZSL"
      },
      "source": [
        "# PREVIEW IMAGES DATA (after augmentation)\n",
        "print(\"SAMPLE OF TRAINING IMAGES (After Augmentation)\")\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn')\n",
        "import tensorflow as tf\n",
        "# Obtain one batch of testing images\n",
        "images, labels = next(train_generator)\n",
        "labels = labels.astype('int')\n",
        "# Plot the images in the batch, along with predicted and true labels\n",
        "nrows = 4\n",
        "ncols = batch_size / nrows\n",
        "fig = plt.figure(figsize=(15, 14))\n",
        "for idx in range(20):\n",
        "    ax = fig.add_subplot(nrows, ncols, idx+1, xticks=[], yticks=[])\n",
        "    plt.imshow(images[idx], cmap=\"bone\")\n",
        "    ax.set_title(classes[labels[idx]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxDMbvnfT5CK"
      },
      "source": [
        "## Deep Learning Model\n",
        "First we try to build standard model with several **Convolution, Maxpooling, and Dense** layer as a base model. Later we try to implement more advanced model by **Transfer Learning** and **Fine Tuning**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePbzwa1CUnu1"
      },
      "source": [
        "### Base Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7uAdK4qUmrY"
      },
      "source": [
        "# Build Model\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
        "\n",
        "model = Sequential([\n",
        "    # Note the input shape is the desired size of the image 224x224 with 3 bytes color\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(256, 256, 3)),\n",
        "    MaxPooling2D(2,2),\n",
        "    Conv2D(32, (3,3), activation='relu'),\n",
        "    MaxPooling2D(2,2), \n",
        "    Conv2D(32, (3,3), activation='relu'), \n",
        "    MaxPooling2D(2,2),\n",
        "    Conv2D(32, (3,3), activation='relu'), \n",
        "    MaxPooling2D(2,2),\n",
        "    Conv2D(32, (3,3), activation='relu'), \n",
        "    MaxPooling2D(2,2),\n",
        "    # Flatten the results to feed into a DNN\n",
        "    Flatten(), \n",
        "    # Dense hidden layer\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(128, activation='relu'),   \n",
        "    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('melanoma') and 1 for the other ('not melanoma')\n",
        "    Dense(1, activation='sigmoid')  \n",
        "])\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsGnlXzLU2RC"
      },
      "source": [
        "# Callback\n",
        "\n",
        "from tensorflow.keras.callbacks import Callback, EarlyStopping\n",
        "class myCallback(Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if(logs.get('accuracy')>0.93):\n",
        "            print(\"\\nReached 93% accuracy so cancelling training!\")\n",
        "            self.model.stop_training = True\n",
        "# callbacks = myCallback()\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U90KG3TmU-3r"
      },
      "source": [
        "# Train the model\n",
        "history = model.fit(train_generator,\n",
        "                    validation_data=test_generator,\n",
        "                    steps_per_epoch=10,\n",
        "                    epochs=35,\n",
        "                    validation_steps=130,\n",
        "                    callbacks=[early_stopping],\n",
        "                    verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERZgveOZXuV8"
      },
      "source": [
        "print(history.history.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoyeA661Ei2-"
      },
      "source": [
        "#### training performance\n",
        "by extracting accuracy and loss parameters during training, we can see how those paramaters evolve for each epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdLk3qNAYLGf"
      },
      "source": [
        "import matplotlib.pyplot as mpl\n",
        "mpl.style.use(\"default\")\n",
        "plt.plot(history.history['accuracy'],'C0')\n",
        "plt.plot(history.history['loss'],'C1')\n",
        "plt.title('Model Training Performance ')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['accucary', 'loss'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjiFqN6qFeMJ"
      },
      "source": [
        "#### heat map of features\n",
        "<p align=\"justify\">By plotting the heat map we can take a look how the convolution layer gives an attention to some specifics parts of the image in order to classify the images. To visualize the heatmap, we will use a technique called Grad-CAM (Gradient Class Activation Map). The idea behind it is quite simple. To find the importance of a certain class in our model, we simply take its gradient with respect to the final convolutional layer and then weigh it against the output of this layer.\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWPtk98z1T8d"
      },
      "source": [
        "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
        "import numpy as np\n",
        "\n",
        "def HeatMapExtract(conv2d_n,class_type):\n",
        "  \"\"\"\n",
        "  return a vector of n-th convolution layer corelates to\n",
        "  a certain_type (0:NORMAL, 1:PNEUMONIA)\n",
        "  \"\"\"\n",
        "\n",
        "  # take a batch of training data (1 batch = 20 images)\n",
        "  images, labels = next(train_generator)\n",
        "\n",
        "  # take a sample of vectorized image from a batch of training images\n",
        "  for i in range (len(labels)):\n",
        "    if labels[i] == class_type:\n",
        "      sample_from_batch_images = images[i]\n",
        "      break\n",
        "\n",
        "  # image vector adjustment to fit the model input\n",
        "  x = image.img_to_array(sample_from_batch_images)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    last_conv_layer = model.get_layer(conv2d_n)\n",
        "    iterate = tf.keras.models.Model([model.inputs], [model.output, last_conv_layer.output])\n",
        "    model_out, last_conv_layer = iterate(x)\n",
        "    class_out = model_out[:, np.argmax(model_out[0])]\n",
        "    grads = tape.gradient(class_out, last_conv_layer)\n",
        "    pooled_grads = backend.mean(grads, axis=(0, 1, 2))\n",
        "    # ceating heat map   \n",
        "    heatmap = tf.reduce_mean(tf.multiply(pooled_grads, last_conv_layer), axis=-1)\n",
        "    heatmap = np.maximum(heatmap, 0)\n",
        "    heatmap /= np.max(heatmap)\n",
        "    hm_shape = heatmap.shape\n",
        "    return heatmap.reshape((hm_shape[1],hm_shape[2]))\n",
        "    \n",
        "HeatMapPneumo = HeatMapExtract(\"conv2d_42\",1)\n",
        "plt.imshow(HeatMapPneumo, cmap=\"jet\")\n",
        "plt.grid(False)\n",
        "plt.title(\"HEAT MAP OF PNEUMONIA\")\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "\n",
        "HeatMapNormal = HeatMapExtract(\"conv2d_42\",0)\n",
        "plt.imshow(HeatMapNormal, cmap=\"jet\")\n",
        "plt.grid(False)\n",
        "plt.title(\"HEAT MAP OF NORMAL\")\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bft21j7ZfEE"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn')\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend\n",
        "import cv2\n",
        "\n",
        "# Obtain one batch of testing images\n",
        "images_test, labels_test = next(test_generator)\n",
        "labels = labels.astype('int')\n",
        "\n",
        "def HeatMapApply (image_vector,heatmap):\n",
        "  INTENSITY = 0.6\n",
        "  img = images[0]\n",
        "  hm = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "  hm = cv2.applyColorMap(np.uint8(255*hm), cv2.COLORMAP_JET)\n",
        "  return (hm/255)*INTENSITY+image_vector\n",
        "\n",
        "# Plot the images in the batch, along with predicted and true labels\n",
        "nrows = 4\n",
        "ncols = batch_size / nrows\n",
        "fig = plt.figure(figsize=(15, 14))\n",
        "for idx in range(10):\n",
        "    ax = fig.add_subplot(nrows, ncols, idx+1, xticks=[], yticks=[])\n",
        "    imhm = HeatMapApply(images[idx], HeatMapPneumo)\n",
        "    plt.imshow(imhm)\n",
        "    ax.set_title(classes[labels[idx]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oESRosR2XBWJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}